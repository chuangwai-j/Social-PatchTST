"""
Social-PatchTSTå®Œæ•´æ¨¡å‹
æ•´åˆæ—¶åºç¼–ç å™¨ã€ç¤¾äº¤ç¼–ç å™¨å’Œé¢„æµ‹è§£ç å™¨
"""

import torch
import torch.nn as nn
import math
from typing import Dict, List, Tuple, Optional

from .patchtst import TemporalEncoder
from .social_transformer import SocialEncoder
from .prediction_decoder import PredictionDecoder
from config.config_manager import load_config


class SocialPatchTST(nn.Module):
    """
    Social-PatchTSTå®Œæ•´æ¨¡å‹

    æ¶æ„ï¼š
    1. Temporal Encoder (PatchTST): å­¦ä¹ å•æ¶é£æœºçš„æ—¶åºæ¨¡å¼
    2. Social Encoder: å­¦ä¹ å¤šæ¶é£æœºä¹‹é—´çš„ç¤¾äº¤äº¤äº’
    3. Prediction Decoder: åŸºäºç¤¾äº¤æ„ŸçŸ¥ç‰¹å¾ç”Ÿæˆæœªæ¥è½¨è¿¹é¢„æµ‹
    """

    def __init__(self, config_path: str, is_baseline: bool = False):
        """
        åˆå§‹åŒ–Social-PatchTSTæ¨¡å‹

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            is_baseline: æ˜¯å¦è¿è¡ŒBaselineæ¨¡å¼ï¼ˆå…³é—­ç¤¾äº¤æ¨¡å—ï¼‰
        """
        super().__init__()

        # åŠ è½½é…ç½®
        self.config = load_config(config_path)
        self.is_baseline = is_baseline  # å­˜å‚¨baselineå¼€å…³
        self.patchtst_config = self.config.patchtst_config
        self.social_config = self.config.social_config
        self.decoder_config = self.config.decoder_config
        self.data_config = self.config.data_config

        # æ—¶åºç¼–ç å™¨ï¼ˆPatchTSTï¼‰
        self.temporal_encoder = TemporalEncoder(self.patchtst_config)

        # ç¤¾äº¤ç¼–ç å™¨
        self.social_encoder = SocialEncoder(self.social_config)

        # é¢„æµ‹è§£ç å™¨
        self.prediction_decoder = PredictionDecoder(self.decoder_config)

        # è®¡ç®—patchæ•°é‡ (T=120, patch_len=16, stride=8)
        self.n_patches = (self.data_config['history_length'] - self.patchtst_config['patch_length']) // self.patchtst_config['stride'] + 1  # = 14

        # === å…³é”®ä¿®å¤ï¼šSocialç‰¹å¾æ± åŒ–å±‚ ===
        # å°†Socialç‰¹å¾ä»æ—¶åºç»´åº¦(T=120)æ± åŒ–åˆ°Patchç»´åº¦(n_patches=14)
        self.social_pool = nn.AdaptiveAvgPool1d(self.n_patches)

        # æŸå¤±æƒé‡
        self.loss_weights = self.config.get('training.loss_weights', {
            'position': 1.0,
            'velocity': 0.5,
            'altitude': 1.0,
            'mindist': 2.0
        })

    def forward(self, batch: Dict[str, torch.Tensor],
                teacher_forcing_ratio: float = 0.5) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­ - æŒ‰è§£å‰–è¡¨è§„èŒƒ

        Args:
            batch: æ‰¹æ¬¡æ•°æ®ï¼Œåº”åŒ…å«ï¼š
                - x_ego: Egoé£æœºæ—¶åº (N, T=120, d=5)
                - x_nbr: é‚»å±…æ—¶åº (N, T=120, K=20, d=5)
                - dist_mx: ç›¸å¯¹è·ç¦» (N, T=120, K)
            teacher_forcing_ratio: æ•™å¸ˆå¼ºåˆ¶æ¯”ä¾‹

        Returns:
            é¢„æµ‹ç»“æœå­—å…¸ï¼ŒåŒ…å«4ä¸ªå¤´çš„é¢„æµ‹
        """
        # ä»batchä¸­æå–è§£å‰–è¡¨è§„èŒƒçš„è¾“å…¥
        x_ego = batch.get('temporal')  # (N, T=120, d=5) - å¦‚æœæ˜¯å•æœºç‰ˆæœ¬
        if x_ego is None:
            # å¦‚æœtemporalæ˜¯å¤šæœºæ ¼å¼ï¼Œå–ç¬¬ä¸€æ¶é£æœºä½œä¸ºego
            temporal_data = batch['temporal']  # [batch_size, n_aircrafts, seq_len, n_temporal_features]
            x_ego = temporal_data[:, 0, :, :]  # å–ç¬¬ä¸€æ¶é£æœºä½œä¸ºego

        # è·å–é‚»å±…æ•°æ® - éœ€è¦æ„å»ºç¬¦åˆè§£å‰–è¡¨çš„æ ¼å¼
        if 'x_nbr' in batch and 'dist_mx' in batch:
            x_nbr = batch['x_nbr']  # (N, T=120, K=20, d=5)
            dist_mx = batch['dist_mx']  # (N, T=120, K)
        else:
            # ä»ç°æœ‰æ•°æ®æ„å»ºé‚»å±…ä¿¡æ¯
            temporal_data = batch['temporal']  # [batch_size, n_aircrafts, seq_len, n_temporal_features]
            distance_matrix = batch['distance_matrix']  # [batch_size, n_aircrafts, n_aircrafts]

            batch_size, n_aircrafts, seq_len, n_temporal_features = temporal_data.shape

            # æ„å»ºé‚»å±…ç‰¹å¾ (N, T=120, K=20, d=5)
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šä½¿ç”¨å…¶ä»–é£æœºä½œä¸ºé‚»å±…
            if n_aircrafts > 1:
                # å–æœ€å¤š20ä¸ªé‚»å±…
                K = min(19, n_aircrafts - 1)  # é™¤äº†egoå¤–çš„é‚»å±…
                x_nbr_list = []
                dist_mx_list = []

                for i in range(batch_size):
                    # egoé£æœºå–ç¬¬ä¸€æ¶
                    ego_temporal = temporal_data[i, 0, :, :]  # egoé£æœº (120, 5)

                    # é‚»å±…é£æœºï¼šä»ç¬¬2æ¶åˆ°ç¬¬min(20, n_aircrafts)æ¶
                    actual_K = min(K, n_aircrafts - 1)
                    neighbor_temporal = temporal_data[i, 1:1+actual_K, :, :]  # (actual_K, 120, 5)
                    neighbor_distances = distance_matrix[i, 0, 1:1+actual_K]  # (actual_K,)

                    # æ‰©å±•ç»´åº¦åˆ°æ—¶åº
                    # neighbor_distances: (actual_K,) -> (actual_K, 1) -> (actual_K, 120)
                    neighbor_distances_expanded = neighbor_distances.unsqueeze(1).expand(-1, seq_len)

                    x_nbr_list.append(neighbor_temporal)  # (actual_K, 120, 5)
                    dist_mx_list.append(neighbor_distances_expanded)  # (actual_K, 120)

                # å †å ä¸ºæ‰¹æ¬¡æ ¼å¼
                x_nbr = torch.stack(x_nbr_list, dim=0)  # (batch_size, actual_K, 120, 5)
                x_nbr = x_nbr.permute(0, 2, 1, 3)  # (batch_size, 120, actual_K, 5)
                dist_mx = torch.stack(dist_mx_list, dim=0)  # (batch_size, actual_K, 120)
                dist_mx = dist_mx.permute(0, 2, 1)  # (batch_size, 120, actual_K)
            else:
                # å¦‚æœæ²¡æœ‰é‚»å±…ï¼Œåˆ›å»ºè™šæ‹Ÿæ•°æ®
                K = 20
                x_nbr = torch.zeros(batch_size, seq_len, K, n_temporal_features, device=x_ego.device)
                dist_mx = torch.full((batch_size, seq_len, K), 9999.0, device=x_ego.device)  # å¾ˆè¿œçš„è·ç¦»

        # === æ¨¡å—ä¸€ï¼šTemporal Encoder (PatchTST) ===
        # å­¦ä¹ egoé£æœºçš„æ—¶åºæ¨¡å¼
        if x_ego.dim() == 3:
            # å¦‚æœæ˜¯3ç»´(N, T, d)ï¼Œéœ€è¦æ·»åŠ n_aircraftsç»´åº¦
            x_ego_expanded = x_ego.unsqueeze(1)  # (N, 1, T, d)
        else:
            # å¦‚æœå·²ç»æ˜¯4ç»´(N, 1, T, d)ï¼Œç›´æ¥ä½¿ç”¨
            x_ego_expanded = x_ego

        encoded_temporal, n_patches = self.temporal_encoder(x_ego_expanded)
        # encoded_temporal: (N, 1, n_patches, d_model) -> (N, n_patches, d_model)
        if encoded_temporal.dim() == 4:
            # encoded_temporal: [N, n_aircrafts, n_patches, d_model]
            # å–ç¬¬ä¸€æ¶é£æœºï¼ˆegoï¼‰çš„ç‰¹å¾
            encoded_temporal = encoded_temporal[:, 0, :, :]  # [N, n_patches, d_model]
        # encoded_temporal: (N, n_patches=14, d_model=512) âœ… PatchTSTè¾“å‡º

        # === æ¨¡å—äºŒï¼šSocial Encoder / Baseline å¼€å…³ ===
        # ğŸ”¥ å…³é”®ï¼šBaselineæ¨¡å¼ vs Social-PatchTSTæ¨¡å¼
        if self.is_baseline:
            # Baselineæ¨¡å¼ï¼šåˆ›å»ºå…¨é›¶çš„"ä¼ªç¤¾äº¤ç‰¹å¾"
            # ç¡®ä¿å®ƒåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼Œå¹¶ä¸”ç»´åº¦åŒ¹é…
            social_patches = torch.zeros_like(encoded_temporal)  # [N, 14, 512]
            social_aware_features = torch.zeros(x_ego.size(0), 120, 512, device=x_ego.device)  # [N, 120, 512]
        else:
            # Social-PatchTSTæ¨¡å¼ï¼šæ­£å¸¸è¿è¡Œç¤¾äº¤æ¨¡å—
            # å­¦ä¹ å¤šæ¶é£æœºä¹‹é—´çš„ç¤¾äº¤äº¤äº’
            social_aware_features = self.social_encoder(x_nbr, dist_mx)
            # social_aware_features: (N, T=120, d_social=512)

            # === æ¨¡å—ä¸‰ï¼šç»´åº¦å¯¹é½ - å…³é”®ä¿®å¤ç‚¹ ===
            # å°†Socialç‰¹å¾ä»æ—¶åºç»´åº¦(T=120)æ± åŒ–åˆ°Patchç»´åº¦(n_patches=14)
            # (N, T, D) -> (N, D, T) -> (N, D, n_patches) -> (N, n_patches, D)
            social_patches = self.social_pool(
                social_aware_features.transpose(1, 2)  # (N, 512, 120)
            ).transpose(1, 2)  # (N, 14, 512)
        # social_patches: (N, n_patches=14, d_social=512) âœ… ä¸PatchTSTç»´åº¦å¯¹é½

        # === æ¨¡å—å››ï¼šæ­£ç¡®çš„èåˆæ–¹å¼ ===
        # åœ¨Patchç»´åº¦ä¸Šèåˆï¼š[N, 14, 512] + [N, 14, 512] -> [N, 14, 1024]
        fused_features = torch.cat([encoded_temporal, social_patches], dim=-1)
        # fused_features: (N, n_patches=14, d_total=1024) âœ… çœŸæ­£ä½¿ç”¨äº†PatchTSTè¾“å‡º

        # === æ¨¡å—äº”ï¼šMLP Heads ===
        # åŸºäºèåˆçš„Patchç‰¹å¾ç”Ÿæˆ4ä¸ªé¢„æµ‹å¤´
        raw_predictions = self.prediction_decoder(fused_features)

        return {
            'predictions': raw_predictions,
            'encoded_temporal': encoded_temporal,
            'social_aware_features': social_aware_features,
            'social_patches': social_patches,  # æ–°å¢ï¼šæš´éœ²æ± åŒ–åçš„socialç‰¹å¾
            'fused_features': fused_features,
            'n_patches': n_patches
        }

    def compute_loss(self, predictions: Dict[str, torch.Tensor], targets: torch.Tensor,
                     distance_matrix: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—å¤šä»»åŠ¡æŸå¤±

        Args:
            predictions: æ¨¡å‹é¢„æµ‹å­—å…¸ï¼ŒåŒ…å«4ä¸ªé¢„æµ‹å¤´çš„è¾“å‡º
            targets: çœŸå®æ ‡ç­¾å¼ é‡ [batch_size, n_aircrafts, seq_len, n_features]
            distance_matrix: è·ç¦»çŸ©é˜µ [batch_size, n_aircrafts, n_aircrafts]

        Returns:
            æŸå¤±å­—å…¸
        """
        device = predictions['position'].device  # ä»ä»»æ„ä¸€ä¸ªé¢„æµ‹å¤´è·å–è®¾å¤‡

        # targetså½¢çŠ¶: [batch_size, n_aircrafts, seq_len, n_features]
        # å–ç¬¬ä¸€æ¶é£æœºï¼ˆegoï¼‰çš„targets: [batch_size, seq_len, n_features]
        ego_targets = targets[:, 0, :, :]  # [batch_size, seq_len, n_features]

        # æ ¹æ®æ•°æ®é›†ï¼Œtargetsçš„æœ€å4ä¸ªç»´åº¦å¯¹åº”ï¼š
        # å‡è®¾targetsçš„4ä¸ªç‰¹å¾é¡ºåºä¸º: [flight_level, latitude, longitude, ground_speed/vx, track_angle/vy]
        # ä½†ä»é”™è¯¯çœ‹ï¼Œå¯èƒ½åªæœ‰4ä¸ªç‰¹å¾ï¼Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´

        # å°†targetsåˆ†å‰²ä»¥åŒ¹é…æˆ‘ä»¬çš„4ä¸ªé¢„æµ‹å¤´
        if ego_targets.size(-1) >= 4:
            # å¦‚æœtargetsæœ‰4ä¸ªæˆ–æ›´å¤šç‰¹å¾
            target_altitude = ego_targets[:, :, 0:1]      # flight_level -> (batch_size, seq_len, 1)
            target_position = ego_targets[:, :, 1:3]      # latitude, longitude -> (batch_size, seq_len, 2)
            target_velocity = ego_targets[:, :, 3:5]      # vx, vy -> (batch_size, seq_len, 2)
        elif ego_targets.size(-1) == 3:
            # å¦‚æœtargetsåªæœ‰3ä¸ªç‰¹å¾ï¼Œéœ€è¦é‡æ–°åˆ†é…
            target_altitude = ego_targets[:, :, 0:1]      # flight_level
            target_position = ego_targets[:, :, 1:3]      # latitude, longitude
            target_velocity = torch.zeros_like(ego_targets[:, :, 0:2])  # åˆ›å»ºè™šæ‹Ÿvelocity
        else:
            raise ValueError(f"Unexpected targets shape: {ego_targets.shape}")

        # åˆ›å»ºè™šæ‹Ÿçš„mindistç›®æ ‡ï¼ˆå¯èƒ½ä¸åŒ…å«åœ¨åŸå§‹targetsä¸­ï¼‰
        target_mindist = torch.zeros(ego_targets.size(0), ego_targets.size(1), 1, device=device)

        # åŸºç¡€å›å½’æŸå¤±
        position_loss = nn.MSELoss()(predictions['position'], target_position)
        altitude_loss = nn.MSELoss()(predictions['altitude'], target_altitude)
        velocity_loss = nn.MSELoss()(predictions['velocity'], target_velocity)

        # æœ€å°è·ç¦»æŸå¤±ï¼ˆmindistçº¦æŸï¼‰
        mindist_loss = self.compute_mindist_loss(predictions['mindist'], distance_matrix)

        # åŠ æƒæ€»æŸå¤±
        total_loss = (
            self.loss_weights['position'] * position_loss +
            self.loss_weights['altitude'] * altitude_loss +
            self.loss_weights['velocity'] * velocity_loss +
            self.loss_weights['mindist'] * mindist_loss
        )

        return {
            'total_loss': total_loss,
            'position_loss': position_loss,
            'altitude_loss': altitude_loss,
            'velocity_loss': velocity_loss,
            'mindist_loss': mindist_loss
        }

    def compute_mindist_loss(self, predictions: torch.Tensor, distance_matrix: torch.Tensor,
                            safety_threshold: float = 5.0, penalty_weight: float = 10.0) -> torch.Tensor:
        """
        è®¡ç®—æœ€å°è·ç¦»æŸå¤±

        Args:
            predictions: mindisté¢„æµ‹ [batch_size, seq_len, 1]
            distance_matrix: å½“å‰è·ç¦»çŸ©é˜µ [batch_size, n_aircrafts, n_aircrafts]
            safety_threshold: å®‰å…¨è·ç¦»é˜ˆå€¼ï¼ˆæµ·é‡Œï¼‰
            penalty_weight: è¿è§„æƒ©ç½šæƒé‡

        Returns:
            æœ€å°è·ç¦»æŸå¤±
        """
        batch_size, seq_len, _ = predictions.shape
        device = predictions.device

        # ç®€åŒ–mindistæŸå¤±ï¼šä½¿ç”¨MSEæŸå¤±ï¼Œé¼“åŠ±mindisté¢„æµ‹å€¼ä¿æŒåˆç†
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå› ä¸ºåŸå§‹çš„mindistè®¡ç®—æ¯”è¾ƒå¤æ‚
        mindist_target = torch.ones_like(predictions) * safety_threshold
        mindist_loss = nn.MSELoss()(predictions, mindist_target)

        return mindist_loss

    def predict(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        æ¨ç†æ¨¡å¼é¢„æµ‹

        Args:
            batch: æ‰¹æ¬¡æ•°æ®

        Returns:
            é¢„æµ‹ç»“æœ
        """
        self.eval()
        with torch.no_grad():
            output = self.forward(batch, teacher_forcing_ratio=0.0)
            return output['predictions']

    def get_model_info(self) -> Dict[str, any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯

        Returns:
            æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)

        return {
            'model_name': 'Social-PatchTST',
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'temporal_encoder_params': sum(p.numel() for p in self.temporal_encoder.parameters()),
            'social_encoder_params': sum(p.numel() for p in self.social_encoder.parameters()),
            'prediction_decoder_params': sum(p.numel() for p in self.prediction_decoder.parameters()),
            'config': {
                'patch_length': self.patchtst_config['patch_length'],
                'stride': self.patchtst_config['stride'],
                'd_model': self.patchtst_config['d_model'],
                'n_heads': self.patchtst_config['n_heads'],
                'history_length': self.data_config['history_length'],
                'prediction_length': self.data_config['prediction_length']
            }
        }


def create_model(config_path: str, is_baseline: bool = False) -> SocialPatchTST:
    """
    åˆ›å»ºSocial-PatchTSTæ¨¡å‹

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        is_baseline: æ˜¯å¦è¿è¡ŒBaselineæ¨¡å¼ï¼ˆå…³é—­ç¤¾äº¤æ¨¡å—ï¼‰

    Returns:
        æ¨¡å‹å®ä¾‹
    """
    model = SocialPatchTST(config_path, is_baseline=is_baseline)
    return model


if __name__ == "__main__":
    # æµ‹è¯•å®Œæ•´æ¨¡å‹
    config_path = "../config/social_patchtst_config.yaml"

    try:
        model = create_model(config_path)

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 2
        n_aircrafts = 5
        seq_len = 120  # 10åˆ†é’Ÿå†å²
        n_temporal_features = 5  # flight_level, ground_speed, track_angle, vertical_rate, selected_altitude

        batch = {
            'temporal': torch.randn(batch_size, n_aircrafts, seq_len, n_temporal_features),
            'spatial': torch.randn(batch_size, n_aircrafts, 2),  # lat, lon
            'targets': torch.randn(batch_size, n_aircrafts, 120, 5),  # 120ä¸ªé¢„æµ‹ç‚¹ï¼Œ5ä¸ªç‰¹å¾
            'distance_matrix': torch.rand(batch_size, n_aircrafts, n_aircrafts) * 20,
            'aircraft_ids': [f'AC{i:03d}' for i in range(batch_size * n_aircrafts)]
        }

        # å‰å‘ä¼ æ’­
        output = model(batch, teacher_forcing_ratio=0.5)

        print(f"é¢„æµ‹ç»“æœå½¢çŠ¶: {output['predictions'].shape}")
        print(f"ç¼–ç æ—¶åºç‰¹å¾å½¢çŠ¶: {output['encoded_temporal'].shape}")
        print(f"ç¤¾äº¤æ„ŸçŸ¥ç‰¹å¾å½¢çŠ¶: {output['social_aware_features'].shape}")
        print(f"Patchæ•°é‡: {output['n_patches']}")

        # è®¡ç®—æŸå¤±
        losses = model.compute_loss(
            output['predictions'], batch['targets'], batch['distance_matrix']
        )
        print(f"æŸå¤±: {losses}")

        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        model_info = model.get_model_info()
        print(f"æ¨¡å‹ä¿¡æ¯: {model_info}")

        print("Social-PatchTSTå®Œæ•´æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")

    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()